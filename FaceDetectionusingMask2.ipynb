{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceDetectionusingMask2.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN9S5lsPD5yY076oKQBzqiB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"t_K3nfVSFRZi"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VyMyhY8qOTCe"},"source":["!pip install keras==2.1.0\n","#!pip install np_utils\n","!pip install tensorflow-gpu==2.1.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKGyijcdOvu-"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","from tqdm import tqdm\n","import keras\n","import tensorflow as tf\n","import time\n","\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","DATADIR = \"/content/drive/MyDrive/Colab Notebooks/Dataset4\"#\"C:/Users/HTC/Desktop/PHD/Visual Field/eye_resize(224,224)\"\n","CATEGORIES = os.listdir(DATADIR)\n"," \n","image_size = 224\n","for category in CATEGORIES:  # do dogs and cats\n","    path = os.path.join(DATADIR,category)  # create path to dogs and cats\n","    for img in os.listdir(path):  # iterate over each image per dogs and cats\n","        img_array = cv2.imread(os.path.join(path,img) )  # convert to array ,cv2.IMREAD_GRAYSCALE\n"," \n","        break  # we just want one for now so break\n","    break \n"," \n","training_data = []\n"," \n","def create_training_data():\n","     for category in CATEGORIES:  # do dogs and cats\n"," \n","        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n","        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n"," \n","        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n","             img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # convert to array ,cv2.IMREAD_GRAYSCALE\n","             new_array = cv2.resize(img_array, (240, 240))  # resize to normalize data size\n","             training_data.append([new_array, class_num])  # add this to our training_data\n"," \n","create_training_data()\n"," \n","print(len(training_data))\n","\n","#start = time.time()\n","\n","X = []\n","y = []\n","\n","for features,label in training_data:\n","    X.append(features)\n","    y.append(label)\n","\n","y = keras.utils.to_categorical(y, num_classes=10)\n","X = np.array(X)#.reshape(-1,1*224*224)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y,shuffle=True,test_size=0.20,stratify=y, random_state=42)\n","x_train = np.repeat(X_train[..., np.newaxis], 3, -1)\n","x_test = np.repeat(X_test[..., np.newaxis], 3, -1)\n","\n","# create generator (1.0/255.0 = 0.003921568627451)\n","datagen = ImageDataGenerator(rescale=1.0/255.0)\n","\n","# prepare an iterators to scale images\n","train_iterator = datagen.flow(x_train, y_train, batch_size=32)\n","test_iterator = datagen.flow(x_test, y_test, batch_size=32)\n","\n","model=VGG16(weights='imagenet',include_top= False,input_shape=(240,240,3))\n","\n","for layer in model.layers:\n","    layer.trainable = False\n","\n","# add new classifier layers\n","flat1 = Flatten()(model.layers[-1].output)\n","#class1 = Dense(1024, activation='relu')(flat1)\n","class2 = Dropout(0.5)(flat1)\n","output = Dense(10, activation='softmax')(class2)\n","# define new model\n","model = Model(inputs=model.inputs, outputs=output)\n","\n","\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","datagen.fit(x_train)    \n","history = model.fit(train_iterator,steps_per_epoch=len(train_iterator), epochs=30,validation_data=(test_iterator))\n","\n","_, acc = model.evaluate(test_iterator, steps=len(test_iterator), verbose=0)\n","print('Test Accuracy: %.3f' % (acc * 100))\n","model.save('vggtest2.h5') \n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9_t72gWUFPHV"},"source":["# import the necessary packages\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import backend as K\n","\n","class SmallerVGGNet:\n","\t@staticmethod\n","\tdef build(width, height, depth, classes, finalAct=\"softmax\"):\n","\t\t# initialize the model along with the input shape to be\n","\t\t# \"channels last\" and the channels dimension itself\n","\t\tmodel = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\t\t# CONV => RELU => POOL\n","\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n","\t\tmodel.add(Dropout(0.25))\n","\t\t# (CONV => RELU) * 2 => POOL\n","\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n","\t\tmodel.add(Dropout(0.25))\n","\t\t# (CONV => RELU) * 2 => POOL\n","\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n","\t\tmodel.add(Dropout(0.25))\n","\t\t# first (and only) set of FC => RELU layers\n","\t\tmodel.add(Flatten())\n","\t\tmodel.add(Dense(1024))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization())\n","\t\tmodel.add(Dropout(0.5))\n","\t\t# softmax classifier\n","\t\tmodel.add(Dense(classes))\n","\t\tmodel.add(Activation(finalAct))\n","\t\t# return the constructed network architecture\n","\t\treturn model\n","\n","\n","# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","# import the necessary packages\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","#from pyimagesearch.smallervggnet import SmallerVGGNet\n","import matplotlib.pyplot as plt\n","from imutils import paths\n","import tensorflow as tf\n","import numpy as np\n","import argparse\n","import random\n","import pickle\n","import cv2\n","import os\n","\n","# initialize the number of epochs to train for, initial learning rate,\n","# batch size, and image dimensions\n","EPOCHS = 30\n","INIT_LR = 1e-3\n","BS = 32\n","IMAGE_DIMS = (96, 96, 3)\n","# disable eager execution\n","tf.compat.v1.disable_eager_execution()\n","\n","# grab the image paths and randomly shuffle them\n","print(\"[INFO] loading images...\")\n","imagePaths = sorted(list(paths.list_images(\"/content/drive/MyDrive/Colab Notebooks/DatasetMLC\")))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","# initialize the data and labels\n","data = []\n","labels = []\n","\n","# loop over the input images\n","for imagePath in imagePaths:\n","\t# load the image, pre-process it, and store it in the data list\n","\timage = cv2.imread(imagePath)\n","\timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n","\timage = img_to_array(image)\n","\tdata.append(image)\n","\t# extract set of class labels from the image path and update the\n","\t# labels list\n","\tl = label = imagePath.split(os.path.sep)[-2].split(\"_\")\n","\tlabels.append(l)\n"," \n","# scale the raw pixel intensities to the range [0, 1]\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(\n","\tlen(imagePaths), data.nbytes / (1024 * 1000.0)))\n","\n","# binarize the labels using scikit-learn's special multi-label\n","# binarizer implementation\n","print(\"[INFO] class labels:\")\n","mlb = MultiLabelBinarizer()\n","labels = mlb.fit_transform(labels)\n","# loop over each of the possible class labels and show them\n","for (i, label) in enumerate(mlb.classes_):\n","\tprint(\"{}. {}\".format(i + 1, label))\n","\n","# partition the data into training and testing splits using 80% of\n","# the data for training and the remaining 20% for testing\n","(trainX, testX, trainY, testY) = train_test_split(data,\n","\tlabels, test_size=0.2, random_state=42)\n","# construct the image generator for data augmentation\n","aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n","\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n","\thorizontal_flip=True, fill_mode=\"nearest\")\n","\n","# initialize the model using a sigmoid activation as the final layer\n","# in the network so we can perform multi-label classification\n","print(\"[INFO] compiling model...\")\n","model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],depth=IMAGE_DIMS[2], classes=len(mlb.classes_),finalAct=\"sigmoid\")\n","# initialize the optimizer (SGD is sufficient)\n","opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n","# train the network\n","print(\"[INFO] training network...\")\n","H = model.fit(\n","\tx=aug.flow(trainX, trainY, batch_size=BS),\n","\tvalidation_data=(testX, testY),\n","\tsteps_per_epoch=len(trainX) // BS,\n","\tepochs=EPOCHS, verbose=1)        \n","\n","# plot the training loss and accuracy\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","N = EPOCHS\n","plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"upper left\")\n","#plt.savefig(args[\"plot\"])"],"execution_count":null,"outputs":[]}]}